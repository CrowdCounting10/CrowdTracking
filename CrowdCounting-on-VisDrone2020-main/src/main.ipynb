{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNbgYnBP1zeE+dAktcxvkGP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dzbIkT_edZty","executionInfo":{"status":"ok","timestamp":1632396636999,"user_tz":-120,"elapsed":17608,"user":{"displayName":"Crowd Counting","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggxj8yyTwIZFwtgzjbo8oEnCP2fPobJQE4kE9ny=s64","userId":"07947164501151212395"}},"outputId":"b8db9128-bdc5-4915-d1b1-1b77d6e77194"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"6Zm2D5O1gOAQ"},"source":["#!unzip \"/content/drive/MyDrive/MobileCount/Generare_density/ObjectDetection/Visdrone2019DET/visdrone2019DET.zip\" -d \"/content/drive/MyDrive/MobileCount/Generare_density/ObjectDetection/Visdrone2019DET/dataset_960x540/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k3V3hRayzKdB","executionInfo":{"status":"ok","timestamp":1632396641110,"user_tz":-120,"elapsed":3333,"user":{"displayName":"Crowd Counting","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggxj8yyTwIZFwtgzjbo8oEnCP2fPobJQE4kE9ny=s64","userId":"07947164501151212395"}},"outputId":"e3de8f1f-b2ac-4ce1-f943-2e26025ecb16"},"source":["!pip install tensorboardX"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorboardX\n","  Downloading tensorboardX-2.4-py2.py3-none-any.whl (124 kB)\n","\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 35.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 30 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 40 kB 16.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 51 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 71 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 81 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 92 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 102 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 112 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 122 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 124 kB 8.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.4\n"]}]},{"cell_type":"code","metadata":{"id":"joq_GbiscWjd","executionInfo":{"status":"ok","timestamp":1632396651193,"user_tz":-120,"elapsed":10088,"user":{"displayName":"Crowd Counting","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggxj8yyTwIZFwtgzjbo8oEnCP2fPobJQE4kE9ny=s64","userId":"07947164501151212395"}}},"source":["import argparse\n","import sys\n","sys.path.append('/content/drive/MyDrive/MobileCount/CrowdCounting-on-VisDrone2020-main/src')\n","\n","from ast import literal_eval\n","from callbacks import call_dict\n","from evaluate import evaluate_model\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","from models.CC import CrowdCounter\n","from dataset.visdrone import load_test, load_train_val, cfg_data\n","from dataset.run_datasets import make_dataset\n","from run import run_model, run_transforms\n","from train import Trainer\n","from config import cfg\n","import numpy as np\n","import torch"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"313ocxTHcd2N","executionInfo":{"status":"ok","timestamp":1632396652033,"user_tz":-120,"elapsed":3,"user":{"displayName":"Crowd Counting","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggxj8yyTwIZFwtgzjbo8oEnCP2fPobJQE4kE9ny=s64","userId":"07947164501151212395"}}},"source":["def load_CC_train():\n","    \"\"\"\n","    Load CrowdCounter model net for training mode\n","    \"\"\"\n","    cc = CrowdCounter([0], cfg.NET)\n","    return cc\n","\n","def load_CC_test():\n","\n","    \"\"\"\n","    Load CrowdCounter model net for testing mode\n","    \"\"\"\n","    cc = CrowdCounter([0], cfg.NET)\n","    if cfg.PRE_TRAINED:\n","        cc.load(cfg.PRE_TRAINED)\n","    return cc\n","\n","# Carica modello pre-trained di Visdrone Object Detection per il fine-tuning di Visdrone Crowd Counting\n","def load_OD_pretrained_train():\n","  PATH = '/content/drive/MyDrive/MobileCount/CrowdCounting-on-VisDrone2020-main/exp/08-25_11-59_VisDrone_MobileCountx0_5_0.001__540x960_NVS_OBJECT_DETECTION_LR1E-3/all_ep_32_mae_10.0_rmse_16.3.pth'\n","  model = CrowdCounter([0], cfg.NET)\n","  checkpoint = torch.load(PATH)\n","  model.load_state_dict(checkpoint['model_state_dict'])\n","\n","  print('Modello pre-trained caricato con successo!')\n"," \n","  return model"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"qQNeq_bocmZO","executionInfo":{"status":"ok","timestamp":1632396652033,"user_tz":-120,"elapsed":2,"user":{"displayName":"Crowd Counting","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggxj8yyTwIZFwtgzjbo8oEnCP2fPobJQE4kE9ny=s64","userId":"07947164501151212395"}}},"source":["def test_net():\n","    \"\"\"\n","    Test a model on a specific test set\n","    Must specify the function tha returns the model and the dataset\n","    \"\"\"\n","    res = evaluate_model(model_function=load_CC_test,\n","                         data_function=load_test,\n","                         bs=cfg.TEST_BATCH_SIZE,\n","                         n_workers=cfg.N_WORKERS,\n","                         losses={'rmse': lambda x, y: mean_squared_error(x, y, squared=False),\n","                                 'mae': mean_absolute_error},\n","                         out_prediction=None\n","                         )\n","    print(res)\n","\n","\n","def run_net(in_file, callbacks):\n","    \"\"\"\n","    Run the model on a given file or folder\n","\n","    @param in_file: media file or folder of images\n","    @param callbacks: list of callbacks to be called after every forward operation\n","    \"\"\"\n","    dataset = make_dataset(in_file)\n","\n","    transforms = run_transforms(cfg_data.MEAN, cfg_data.STD, cfg_data.SIZE)\n","    dataset.set_transforms(transforms)\n","\n","    callbacks_list = [(call_dict[call] if type(call) == str else call) for call in callbacks]\n","\n","    run_model(load_CC_test, dataset, cfg.TEST_BATCH_SIZE, cfg.N_WORKERS, callbacks_list)\n","\n","\n","def train_net():\n","    \"\"\"\n","    Train the given model on a given data loader\n","    \"\"\"\n","    trainer = Trainer(dataloader=load_train_val,\n","                      cfg_data=cfg_data,\n","                      net_fun=load_CC_train\n","                      )\n","    \n","    trainer.train()\n","\n","\n","def train_net_pretrained():\n","    \"\"\"\n","    Train the given model on a given data loader\n","    \"\"\"\n","    trainer = Trainer(dataloader=load_train_val,\n","                      cfg_data=cfg_data,\n","                      net_fun=load_OD_pretrained_train\n","                      )\n","    \n","    trainer.train()"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ZSY3kIVcrra"},"source":["if __name__ == '__main__':\n","    seed = cfg.SEED\n","    if seed is not None:\n","        np.random.seed(seed)\n","        torch.manual_seed(seed)\n","        torch.cuda.manual_seed(seed)\n","\n","    parser = argparse.ArgumentParser(description='Execute a training, an evaluation or run the net on some example')\n","    parser.add_argument('mode', type=str, help='can be train, test or run')\n","    parser.add_argument('--path', type=str, help='in run mode, the input file or folder to be processed')\n","    parser.add_argument('--callbacks', type=str,\n","                        help='List of callbacks, they can be [\\'save_callback\\', \\'count_callback\\']')\n","    #args = parser.parse_args()\n","    train_net()\n","    #train_net_pretrained()\n","    #test_net()\n","\n","''' if args.callbacks is not None:\n","        callbacks = literal_eval(args.callbacks)\n","    else:\n","        callbacks = []\n","    if args.mode == 'train':\n","        train_net()\n","    elif args.mode == 'test':\n","        test_net()\n","    elif args.mode == 'run':\n","        run_net(args.path, callbacks)'''\n","\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fZ9zCm9fU3-n","executionInfo":{"status":"ok","timestamp":1632397003131,"user_tz":-120,"elapsed":578,"user":{"displayName":"Crowd Counting","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggxj8yyTwIZFwtgzjbo8oEnCP2fPobJQE4kE9ny=s64","userId":"07947164501151212395"}},"outputId":"c1595eb3-d3cc-45ea-f8f5-4c45fbe5896a"},"source":["#TAKE GT COUNT\n","import h5py\n","import torch\n","from tqdm import tqdm\n","from dataset.visdrone import load_test, load_train_val, cfg_data\n","import cv2\n","\n","train_loader, val_loader = load_train_val()\n","\n","tk_train = tqdm(\n","            enumerate(train_loader, 0), total=len(train_loader), leave=False,bar_format='{l_bar}{bar:32}{r_bar}',\n","            colour='#ff0de7')\n","        \n","for i, data in tk_train:\n","    img, gt = data\n","    gt = gt.to('cuda')\n","    img = img.to('cuda')\n","\n","    norm_gt_count = torch.mean(torch.sum(gt, dim=(1, 2))).data / 2550.0\n","    print('gt count: ')\n","    print(norm_gt_count.item())"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Visdrone train = True\n","Visdrone img_transform = True\n","Visdrone gt_transform = True\n","Visdrone train = True\n","Visdrone img_transform = True\n","Visdrone gt_transform = True\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","                                                                   "]},{"output_type":"stream","name":"stdout","text":["gt count: \n","207.60107421875\n"]},{"output_type":"stream","name":"stderr","text":["\r"]}]}]}